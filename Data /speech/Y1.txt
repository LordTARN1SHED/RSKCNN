Epoch 1/20
1323/1323 [==============================] - 23s 16ms/step - loss: 1.0345 - accuracy: 0.7146 - val_loss: 0.5207 - val_accuracy: 0.8474
Epoch 2/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.4284 - accuracy: 0.8738 - val_loss: 0.4941 - val_accuracy: 0.8652
Epoch 3/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.3240 - accuracy: 0.9008 - val_loss: 0.4385 - val_accuracy: 0.8798
Epoch 4/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.2876 - accuracy: 0.9119 - val_loss: 0.4237 - val_accuracy: 0.8822
Epoch 5/20
1319/1323 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.9132WARNING:tensorflow:5 out of the last 5 calls to <function SparseConv2D.update_p at 0x000001FEA1994430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
1323/1323 [==============================] - 16s 12ms/step - loss: 0.2775 - accuracy: 0.9132 - val_loss: 0.3949 - val_accuracy: 0.8942
Epoch 6/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.2938 - accuracy: 0.9087 - val_loss: 0.3846 - val_accuracy: 0.8902
Epoch 7/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.2557 - accuracy: 0.9203 - val_loss: 0.3611 - val_accuracy: 0.9017
Epoch 8/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.2310 - accuracy: 0.9277 - val_loss: 0.4142 - val_accuracy: 0.8956
Epoch 9/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.2168 - accuracy: 0.9325 - val_loss: 0.3931 - val_accuracy: 0.8997
Epoch 10/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1984 - accuracy: 0.9381 - val_loss: 0.3735 - val_accuracy: 0.8993
Epoch 11/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1879 - accuracy: 0.9408 - val_loss: 0.3848 - val_accuracy: 0.9040
Epoch 12/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1703 - accuracy: 0.9469 - val_loss: 0.3759 - val_accuracy: 0.9007
Epoch 13/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1656 - accuracy: 0.9479 - val_loss: 0.3856 - val_accuracy: 0.9040
Epoch 14/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1521 - accuracy: 0.9522 - val_loss: 0.4143 - val_accuracy: 0.9071
Epoch 15/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1456 - accuracy: 0.9536 - val_loss: 0.4007 - val_accuracy: 0.9070
Epoch 16/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1356 - accuracy: 0.9573 - val_loss: 0.3941 - val_accuracy: 0.9044
Epoch 17/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1316 - accuracy: 0.9587 - val_loss: 0.4369 - val_accuracy: 0.9024
Epoch 18/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1284 - accuracy: 0.9601 - val_loss: 0.4138 - val_accuracy: 0.9067
Epoch 19/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1178 - accuracy: 0.9639 - val_loss: 0.4173 - val_accuracy: 0.9076
Epoch 20/20
1323/1323 [==============================] - 16s 12ms/step - loss: 0.1156 - accuracy: 0.9651 - val_loss: 0.4037 - val_accuracy: 0.9037
166/166 [==============================] - 3s 15ms/step - loss: 0.4295 - accuracy: 0.9027
Test accuracy: 0.9026833176612854