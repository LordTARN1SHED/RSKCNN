{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cdcee65-a285-4c5e-9d9f-b82d6c7ce21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0be1b1-17b0-4621-9a4a-e9a108bc4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f4cdf7-0b8a-495d-bf16-f48d6f6bdac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data by adding a channel dimension and normalizing\n",
    "mnist_train_images = mnist_train_images.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "mnist_test_images = mnist_test_images.reshape(-1, 28, 28, 1).astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8800841e-2ac6-423c-8b23-7975032515be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseConv2D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, p, **kwargs):\n",
    "        super(SparseConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.p = tf.Variable(float(p), trainable=False)  # 将 p 转换为浮点数类型\n",
    "        self.counter = tf.Variable(0, trainable=False, dtype=tf.int32)  # 初始化计数器\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(self.kernel_size, self.kernel_size, input_shape[-1], self.filters),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.filters,),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            mask = tf.random.uniform(shape=(self.filters,), minval=0, maxval=1)\n",
    "            mask = tf.cast(mask < self.p, dtype=tf.float32)\n",
    "            mask = tf.reshape(mask, [1, 1, 1, self.filters])\n",
    "            #self.counter.assign_add(1)  # 更新计数器\n",
    "            #tf.print(\"\\nP is\", self.p)  # 使用 tf.print\n",
    "        else:\n",
    "            mask = tf.ones([1, 1, 1, self.filters], dtype=tf.float32) * self.p\n",
    "    \n",
    "        sparse_kernel = self.kernel * mask\n",
    "        conv = tf.nn.conv2d(inputs, sparse_kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        return tf.nn.bias_add(conv, self.bias)\n",
    "\n",
    "    @tf.function\n",
    "    def update_p(self, new_p):\n",
    "        self.p.assign(float(new_p))  # 使用 assign 更新 tf.Variable 的值，并转换为浮点数\n",
    "        #tf.print(\"\\nEpoch counter is\", self.counter)  # 使用 tf.print\n",
    "        #tf.print(\"\\nP is\", self.p)  # 使用 tf.print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af584832-32c4-4de9-b939-67177aa1f8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "sparse_conv2d_1 (SparseConv2 (None, 28, 28, 32)        322       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "sparse_conv2d_2 (SparseConv2 (None, 14, 14, 64)        18498     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "sparse_conv2d_3 (SparseConv2 (None, 7, 7, 128)         73858     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 904,528\n",
      "Trainable params: 904,522\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28, 1))  # Adjusted input shape for MNIST\n",
    "x = SparseConv2D(filters=32, kernel_size=3, p=1, name='sparse_conv2d_1')(inputs)  # 第一个稀疏卷积层\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = SparseConv2D(filters=64, kernel_size=3, p=1, name='sparse_conv2d_2')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = SparseConv2D(filters=128, kernel_size=3, p=1, name='sparse_conv2d_3')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)  # Adjusted for 10 classes of MNIST\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ed562d-2bb0-428c-9b45-450d274f6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatePSparsity(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, sparsity_schedule):\n",
    "        super(UpdatePSparsity, self).__init__()\n",
    "        self.model = model\n",
    "        self.sparsity_schedule = sparsity_schedule\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for layer_name, new_p in self.sparsity_schedule.items():\n",
    "            layer = self.model.get_layer(name=layer_name)\n",
    "            if epoch < len(new_p):\n",
    "                p_value = new_p[epoch]\n",
    "            else:\n",
    "                p_value = new_p[-1]  # Use the last value for epochs beyond the predefined ones\n",
    "            layer.update_p(p_value)\n",
    "\n",
    "sparsity_schedule = {\n",
    "    'sparse_conv2d_1': [1.0],\n",
    "    'sparse_conv2d_2': [1.0],\n",
    "    'sparse_conv2d_3': [0.9,0.8,0.7,0.6,0.5,0.4,0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7da4c9e-89ea-41d4-8459-818726bf82d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 2ms/step - loss: 0.4845 - accuracy: 0.8217 - val_loss: 0.3448 - val_accuracy: 0.8776\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2989 - accuracy: 0.8912 - val_loss: 0.2892 - val_accuracy: 0.8943\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2582 - accuracy: 0.9043 - val_loss: 0.2739 - val_accuracy: 0.8987\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function SparseConv2D.update_p at 0x0000017B5534E1F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2368 - accuracy: 0.9129 - val_loss: 0.2820 - val_accuracy: 0.8961\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function SparseConv2D.update_p at 0x0000017B5534E1F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2253 - accuracy: 0.9165 - val_loss: 0.2440 - val_accuracy: 0.9102\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2134 - accuracy: 0.9211 - val_loss: 0.2366 - val_accuracy: 0.9136\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2128 - accuracy: 0.9207 - val_loss: 0.2245 - val_accuracy: 0.9190\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2200 - accuracy: 0.9182 - val_loss: 0.2237 - val_accuracy: 0.9191\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2084 - accuracy: 0.9228 - val_loss: 0.2293 - val_accuracy: 0.9164\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1967 - accuracy: 0.9269 - val_loss: 0.2165 - val_accuracy: 0.9229\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1885 - accuracy: 0.9299 - val_loss: 0.2153 - val_accuracy: 0.9218\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1805 - accuracy: 0.9332 - val_loss: 0.2085 - val_accuracy: 0.9239\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1732 - accuracy: 0.9360 - val_loss: 0.2163 - val_accuracy: 0.9226\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1693 - accuracy: 0.9365 - val_loss: 0.2131 - val_accuracy: 0.9248\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1634 - accuracy: 0.9384 - val_loss: 0.2068 - val_accuracy: 0.9247\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1565 - accuracy: 0.9419 - val_loss: 0.2030 - val_accuracy: 0.9273\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1492 - accuracy: 0.9440 - val_loss: 0.2057 - val_accuracy: 0.9230\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1454 - accuracy: 0.9461 - val_loss: 0.2006 - val_accuracy: 0.9310\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1425 - accuracy: 0.9470 - val_loss: 0.2069 - val_accuracy: 0.9289\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1379 - accuracy: 0.9481 - val_loss: 0.2093 - val_accuracy: 0.9293\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1332 - accuracy: 0.9503 - val_loss: 0.2051 - val_accuracy: 0.9281\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1286 - accuracy: 0.9519 - val_loss: 0.2116 - val_accuracy: 0.9260\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1215 - accuracy: 0.9543 - val_loss: 0.2086 - val_accuracy: 0.9264\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1190 - accuracy: 0.9548 - val_loss: 0.2096 - val_accuracy: 0.9303\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1213 - accuracy: 0.9544 - val_loss: 0.2186 - val_accuracy: 0.9282\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1157 - accuracy: 0.9562 - val_loss: 0.2163 - val_accuracy: 0.9303\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1110 - accuracy: 0.9574 - val_loss: 0.2115 - val_accuracy: 0.9281\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1073 - accuracy: 0.9587 - val_loss: 0.2112 - val_accuracy: 0.9289\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1053 - accuracy: 0.9598 - val_loss: 0.2169 - val_accuracy: 0.9287\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1035 - accuracy: 0.9608 - val_loss: 0.2188 - val_accuracy: 0.9287\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0975 - accuracy: 0.9634 - val_loss: 0.2089 - val_accuracy: 0.9310\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0958 - accuracy: 0.9638 - val_loss: 0.2182 - val_accuracy: 0.9298\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0956 - accuracy: 0.9645 - val_loss: 0.2212 - val_accuracy: 0.9283\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0929 - accuracy: 0.9647 - val_loss: 0.2120 - val_accuracy: 0.9316\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0879 - accuracy: 0.9653 - val_loss: 0.2305 - val_accuracy: 0.9317\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0903 - accuracy: 0.9663 - val_loss: 0.2280 - val_accuracy: 0.9290\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0847 - accuracy: 0.9680 - val_loss: 0.2191 - val_accuracy: 0.9320\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0845 - accuracy: 0.9679 - val_loss: 0.2269 - val_accuracy: 0.9335\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0827 - accuracy: 0.9692 - val_loss: 0.2337 - val_accuracy: 0.9278\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0823 - accuracy: 0.9690 - val_loss: 0.2247 - val_accuracy: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17783fbcf08>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(mnist_train_images, mnist_train_labels, epochs=40, batch_size=128, validation_data=(mnist_test_images, mnist_test_labels), callbacks=[UpdatePSparsity(model, sparsity_schedule)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
