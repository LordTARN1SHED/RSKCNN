{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46bb9098-8178-42ce-9fd0-bc506bc183d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e60d65f-7077-4c36-af80-d24e8d017a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 数据集路径\n",
    "data_dir = '/root/SKCNNs/256_ObjectCategories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e926149-87a0-466f-bc20-782104a8a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    # 将图像尺寸调整为稍大的尺寸，然后随机裁剪到最终的 224x224 尺寸\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = tf.image.random_crop(image, size=[224, 224, 3])\n",
    "    # 可选：增加随机翻转\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # 归一化图像到 [0, 1] 范围\n",
    "    image = image / 255.0\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d64aca6f-7ce6-41bb-9805-49128c9bd5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30607 files belonging to 257 classes.\n",
      "Using 24486 files for training.\n",
      "Found 30607 files belonging to 257 classes.\n",
      "Using 6121 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# 加载训练和验证数据集\n",
    "batch_size = 16\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e163127-ee3e-429f-8d07-6ea4cd0d297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseConv2D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, p, **kwargs):\n",
    "        super(SparseConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.p = tf.Variable(float(p), trainable=False)  # 将 p 转换为浮点数类型\n",
    "        self.counter = tf.Variable(0, trainable=False, dtype=tf.int32)  # 初始化计数器\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(self.kernel_size, self.kernel_size, input_shape[-1], self.filters),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.filters,),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            mask = tf.random.uniform(shape=(self.filters,), minval=0, maxval=1)\n",
    "            mask = tf.cast(mask < self.p, dtype=tf.float32)\n",
    "            mask = tf.reshape(mask, [1, 1, 1, self.filters])\n",
    "            #self.counter.assign_add(1)  # 更新计数器\n",
    "            #tf.print(\"\\nP is\", self.p)  # 使用 tf.print\n",
    "        else:\n",
    "            mask = tf.ones([1, 1, 1, self.filters], dtype=tf.float32) * self.p\n",
    "    \n",
    "        sparse_kernel = self.kernel * mask\n",
    "        conv = tf.nn.conv2d(inputs, sparse_kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        return tf.nn.bias_add(conv, self.bias)\n",
    "\n",
    "    @tf.function\n",
    "    def update_p(self, new_p):\n",
    "        self.p.assign(float(new_p))  # 使用 assign 更新 tf.Variable 的值，并转换为浮点数\n",
    "        #tf.print(\"\\nEpoch counter is\", self.counter)  # 使用 tf.print\n",
    "        #tf.print(\"\\nP is\", self.p)  # 使用 tf.print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "101afdea-93c2-4f28-9c7a-42ba2a94734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用预处理，并设置批次大小和乱序缓冲区大小\n",
    "train_data = train_data.map(lambda x, y: (tf.map_fn(lambda img: preprocess(img, y)[0], x, dtype=tf.float32), y)).shuffle(1000).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_data = val_data.map(lambda x, y: (tf.map_fn(lambda img: preprocess(img, y)[0], x, dtype=tf.float32), y)).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c7948e8-ad3a-4d14-b4a9-0d12c2c1e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 54, 54, 96)       384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 26, 26, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 26, 26, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 12, 12, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 384)       885120    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 384)       1327488   \n",
      "                                                                 \n",
      " sparse_conv2d (SparseConv2D  (None, 12, 12, 256)      884994    \n",
      " )                                                               \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              26218496  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 257)               1052929   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,801,347\n",
      "Trainable params: 47,800,641\n",
      "Non-trainable params: 706\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 使用较小的学习率和 Adam 优化器\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "def alexnet_model(input_shape=(224, 224, 3), num_classes=257):\n",
    "    model = Sequential([\n",
    "        Conv2D(96, kernel_size=11, strides=4, padding='valid', activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=3, strides=2),\n",
    "        Conv2D(256, kernel_size=5, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=3, strides=2),\n",
    "        Conv2D(384, kernel_size=3, padding='same', activation='relu'),\n",
    "        Conv2D(384, kernel_size=3, padding='same', activation='relu'),\n",
    "        SparseConv2D(filters=256, kernel_size=3, p=1, name='sparse_conv2d'),\n",
    "        MaxPooling2D(pool_size=3, strides=2),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 创建模型\n",
    "model = alexnet_model()\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 模型摘要\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48683d03-138f-4125-8f0e-2d74f892dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatePSparsity(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, sparsity_schedule):\n",
    "        super(UpdatePSparsity, self).__init__()\n",
    "        self.model = model\n",
    "        self.sparsity_schedule = sparsity_schedule\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for layer_name, new_p in self.sparsity_schedule.items():\n",
    "            layer = self.model.get_layer(name=layer_name)\n",
    "            if epoch < len(new_p):\n",
    "                p_value = new_p[epoch]\n",
    "            else:\n",
    "                p_value = new_p[-1]  # Use the last value for epochs beyond the predefined ones\n",
    "            layer.update_p(p_value)\n",
    "            #print(f\"\\nEpoch {epoch + 1}: Updated layer {layer_name} sparsity p to {p_value}\")\n",
    "\n",
    "sparsity_schedule = {\n",
    "    'sparse_conv2d': [1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f767934c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1531/1531 [==============================] - 18s 9ms/step - loss: 5.0504 - accuracy: 0.0877 - val_loss: 4.5405 - val_accuracy: 0.1379\n",
      "Epoch 2/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 4.4292 - accuracy: 0.1434 - val_loss: 4.3388 - val_accuracy: 0.1617\n",
      "Epoch 3/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 3.9923 - accuracy: 0.2008 - val_loss: 3.8322 - val_accuracy: 0.2325\n",
      "Epoch 4/40\n",
      "1531/1531 [==============================] - 18s 9ms/step - loss: 3.6307 - accuracy: 0.2520 - val_loss: 3.8417 - val_accuracy: 0.2325\n",
      "Epoch 5/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 3.3111 - accuracy: 0.3004 - val_loss: 3.5869 - val_accuracy: 0.2759\n",
      "Epoch 6/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 3.0478 - accuracy: 0.3401 - val_loss: 3.3916 - val_accuracy: 0.3053\n",
      "Epoch 7/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 2.8029 - accuracy: 0.3810 - val_loss: 3.0328 - val_accuracy: 0.3607\n",
      "Epoch 8/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 2.5884 - accuracy: 0.4169 - val_loss: 2.9583 - val_accuracy: 0.3762\n",
      "Epoch 9/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 2.3897 - accuracy: 0.4511 - val_loss: 2.9488 - val_accuracy: 0.3722\n",
      "Epoch 10/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 2.2183 - accuracy: 0.4860 - val_loss: 2.8803 - val_accuracy: 0.3911\n",
      "Epoch 11/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 2.0325 - accuracy: 0.5165 - val_loss: 3.0447 - val_accuracy: 0.3759\n",
      "Epoch 12/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 1.8867 - accuracy: 0.5452 - val_loss: 2.8676 - val_accuracy: 0.3983\n",
      "Epoch 13/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 1.7358 - accuracy: 0.5727 - val_loss: 2.8283 - val_accuracy: 0.4091\n",
      "Epoch 14/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 1.5959 - accuracy: 0.6054 - val_loss: 2.9246 - val_accuracy: 0.4048\n",
      "Epoch 15/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 1.4845 - accuracy: 0.6245 - val_loss: 2.8561 - val_accuracy: 0.4233\n",
      "Epoch 16/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 1.3690 - accuracy: 0.6482 - val_loss: 2.9667 - val_accuracy: 0.4097\n",
      "Epoch 17/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 1.2724 - accuracy: 0.6710 - val_loss: 2.8483 - val_accuracy: 0.4253\n",
      "Epoch 18/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 1.1865 - accuracy: 0.6857 - val_loss: 2.9524 - val_accuracy: 0.4215\n",
      "Epoch 19/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 1.1124 - accuracy: 0.7068 - val_loss: 2.9592 - val_accuracy: 0.4199\n",
      "Epoch 20/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 1.0415 - accuracy: 0.7212 - val_loss: 2.9162 - val_accuracy: 0.4315\n",
      "Epoch 21/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 0.9872 - accuracy: 0.7370 - val_loss: 2.9350 - val_accuracy: 0.4308\n",
      "Epoch 22/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 0.9328 - accuracy: 0.7470 - val_loss: 3.0427 - val_accuracy: 0.4362\n",
      "Epoch 23/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 0.8773 - accuracy: 0.7644 - val_loss: 3.0613 - val_accuracy: 0.4300\n",
      "Epoch 24/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 0.8277 - accuracy: 0.7724 - val_loss: 3.1747 - val_accuracy: 0.4306\n",
      "Epoch 25/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 0.7987 - accuracy: 0.7791 - val_loss: 3.0627 - val_accuracy: 0.4365\n",
      "Epoch 26/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 0.7724 - accuracy: 0.7900 - val_loss: 3.1214 - val_accuracy: 0.4215\n",
      "Epoch 27/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 0.7305 - accuracy: 0.7989 - val_loss: 3.0509 - val_accuracy: 0.4292\n",
      "Epoch 28/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 0.7066 - accuracy: 0.8042 - val_loss: 3.0875 - val_accuracy: 0.4408\n",
      "Epoch 29/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 0.6771 - accuracy: 0.8131 - val_loss: 3.0606 - val_accuracy: 0.4419\n",
      "Epoch 30/40\n",
      "1531/1531 [==============================] - 17s 9ms/step - loss: 0.6593 - accuracy: 0.8164 - val_loss: 3.3272 - val_accuracy: 0.4302\n",
      "Epoch 31/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 0.6248 - accuracy: 0.8259 - val_loss: 3.2998 - val_accuracy: 0.4315\n",
      "Epoch 32/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 0.6211 - accuracy: 0.8263 - val_loss: 3.3784 - val_accuracy: 0.4217\n",
      "Epoch 33/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 0.6108 - accuracy: 0.8301 - val_loss: 3.2402 - val_accuracy: 0.4349\n",
      "Epoch 34/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 0.5878 - accuracy: 0.8370 - val_loss: 3.3014 - val_accuracy: 0.4365\n",
      "Epoch 35/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 0.5634 - accuracy: 0.8426 - val_loss: 3.2562 - val_accuracy: 0.4387\n",
      "Epoch 36/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 0.5507 - accuracy: 0.8473 - val_loss: 3.4920 - val_accuracy: 0.4387\n",
      "Epoch 37/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 0.5468 - accuracy: 0.8471 - val_loss: 3.4501 - val_accuracy: 0.4419\n",
      "Epoch 38/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 0.5408 - accuracy: 0.8500 - val_loss: 3.2661 - val_accuracy: 0.4391\n",
      "Epoch 39/40\n",
      "1531/1531 [==============================] - 17s 8ms/step - loss: 0.5221 - accuracy: 0.8524 - val_loss: 3.4257 - val_accuracy: 0.4295\n",
      "Epoch 40/40\n",
      "1531/1531 [==============================] - 16s 8ms/step - loss: 0.5018 - accuracy: 0.8603 - val_loss: 3.4419 - val_accuracy: 0.4373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd32026ad30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型，并在验证集上验证\n",
    "model.fit( train_data, epochs=40, validation_data=val_data, callbacks=[UpdatePSparsity(model, sparsity_schedule)] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
