{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cdcee65-a285-4c5e-9d9f-b82d6c7ce21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0be1b1-17b0-4621-9a4a-e9a108bc4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f4cdf7-0b8a-495d-bf16-f48d6f6bdac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data by adding a channel dimension and normalizing\n",
    "mnist_train_images = mnist_train_images.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "mnist_test_images = mnist_test_images.reshape(-1, 28, 28, 1).astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8800841e-2ac6-423c-8b23-7975032515be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseConv2D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, p, **kwargs):\n",
    "        super(SparseConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.p = tf.Variable(float(p), trainable=False)  # 将 p 转换为浮点数类型\n",
    "        self.counter = tf.Variable(0, trainable=False, dtype=tf.int32)  # 初始化计数器\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(self.kernel_size, self.kernel_size, input_shape[-1], self.filters),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.filters,),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            mask = tf.random.uniform(shape=(self.filters,), minval=0, maxval=1)\n",
    "            mask = tf.cast(mask < self.p, dtype=tf.float32)\n",
    "            mask = tf.reshape(mask, [1, 1, 1, self.filters])\n",
    "            #self.counter.assign_add(1)  # 更新计数器\n",
    "            #tf.print(\"\\nP is\", self.p)  # 使用 tf.print\n",
    "        else:\n",
    "            mask = tf.ones([1, 1, 1, self.filters], dtype=tf.float32) * self.p\n",
    "    \n",
    "        sparse_kernel = self.kernel * mask\n",
    "        conv = tf.nn.conv2d(inputs, sparse_kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        return tf.nn.bias_add(conv, self.bias)\n",
    "\n",
    "    @tf.function\n",
    "    def update_p(self, new_p):\n",
    "        self.p.assign(float(new_p))  # 使用 assign 更新 tf.Variable 的值，并转换为浮点数\n",
    "        #tf.print(\"\\nEpoch counter is\", self.counter)  # 使用 tf.print\n",
    "        #tf.print(\"\\nP is\", self.p)  # 使用 tf.print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af584832-32c4-4de9-b939-67177aa1f8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "sparse_conv2d_1 (SparseConv2 (None, 28, 28, 32)        322       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "sparse_conv2d_2 (SparseConv2 (None, 14, 14, 64)        18498     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "sparse_conv2d_3 (SparseConv2 (None, 7, 7, 128)         73858     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 904,528\n",
      "Trainable params: 904,522\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28, 1))  # Adjusted input shape for MNIST\n",
    "x = SparseConv2D(filters=32, kernel_size=3, p=1, name='sparse_conv2d_1')(inputs)  # 第一个稀疏卷积层\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = SparseConv2D(filters=64, kernel_size=3, p=1, name='sparse_conv2d_2')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = SparseConv2D(filters=128, kernel_size=3, p=1, name='sparse_conv2d_3')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)  # Adjusted for 10 classes of MNIST\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ed562d-2bb0-428c-9b45-450d274f6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatePSparsity(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, sparsity_schedule):\n",
    "        super(UpdatePSparsity, self).__init__()\n",
    "        self.model = model\n",
    "        self.sparsity_schedule = sparsity_schedule\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for layer_name, new_p in self.sparsity_schedule.items():\n",
    "            layer = self.model.get_layer(name=layer_name)\n",
    "            if epoch < len(new_p):\n",
    "                p_value = new_p[epoch]\n",
    "            else:\n",
    "                p_value = new_p[-1]  # Use the last value for epochs beyond the predefined ones\n",
    "            layer.update_p(p_value)\n",
    "\n",
    "sparsity_schedule = {\n",
    "    'sparse_conv2d_1': [1.0],\n",
    "    'sparse_conv2d_2': [1.0],\n",
    "    'sparse_conv2d_3': [1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7da4c9e-89ea-41d4-8459-818726bf82d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 2ms/step - loss: 0.1897 - accuracy: 0.9413 - val_loss: 0.0454 - val_accuracy: 0.9854\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.0345 - val_accuracy: 0.9890\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0313 - accuracy: 0.9904 - val_loss: 0.0327 - val_accuracy: 0.9892\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0308 - val_accuracy: 0.9902\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0315 - val_accuracy: 0.9896\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.0271 - val_accuracy: 0.9904\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0287 - val_accuracy: 0.9919\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0358 - val_accuracy: 0.9908\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0292 - val_accuracy: 0.9922\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0302 - val_accuracy: 0.9915\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0335 - val_accuracy: 0.9907\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0338 - val_accuracy: 0.9908\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0371 - val_accuracy: 0.9918\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0294 - val_accuracy: 0.9919\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0325 - val_accuracy: 0.9920\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0312 - val_accuracy: 0.9919\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0318 - val_accuracy: 0.9927\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0375 - val_accuracy: 0.9929\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0383 - val_accuracy: 0.9903\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0427 - val_accuracy: 0.9904\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0397 - val_accuracy: 0.9921\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0458 - val_accuracy: 0.9914\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.0386 - val_accuracy: 0.9919\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0361 - val_accuracy: 0.9930\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0433 - val_accuracy: 0.9917\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0397 - val_accuracy: 0.9918\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0461 - val_accuracy: 0.9927\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0440 - val_accuracy: 0.9924\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0482 - val_accuracy: 0.9907\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0466 - val_accuracy: 0.9913\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0450 - val_accuracy: 0.9915\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0377 - val_accuracy: 0.9930\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0392 - val_accuracy: 0.9925\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0367 - val_accuracy: 0.9933\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 9.2374e-04 - accuracy: 0.9997 - val_loss: 0.0324 - val_accuracy: 0.9931\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0366 - val_accuracy: 0.9924\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0417 - val_accuracy: 0.9932\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0485 - val_accuracy: 0.9917\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0438 - val_accuracy: 0.9909\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0568 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2577f1f0448>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(mnist_train_images, mnist_train_labels, epochs=40, batch_size=128, validation_data=(mnist_test_images, mnist_test_labels), callbacks=[UpdatePSparsity(model, sparsity_schedule)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
