{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cdcee65-a285-4c5e-9d9f-b82d6c7ce21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0be1b1-17b0-4621-9a4a-e9a108bc4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f4cdf7-0b8a-495d-bf16-f48d6f6bdac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data by adding a channel dimension and normalizing\n",
    "mnist_train_images = mnist_train_images.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "mnist_test_images = mnist_test_images.reshape(-1, 28, 28, 1).astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8800841e-2ac6-423c-8b23-7975032515be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseConv2D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, p, **kwargs):\n",
    "        super(SparseConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.p = tf.Variable(float(p), trainable=False)  # 将 p 转换为浮点数类型\n",
    "        self.counter = tf.Variable(0, trainable=False, dtype=tf.int32)  # 初始化计数器\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(self.kernel_size, self.kernel_size, input_shape[-1], self.filters),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.filters,),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            mask = tf.random.uniform(shape=(self.filters,), minval=0, maxval=1)\n",
    "            mask = tf.cast(mask < self.p, dtype=tf.float32)\n",
    "            mask = tf.reshape(mask, [1, 1, 1, self.filters])\n",
    "            #self.counter.assign_add(1)  # 更新计数器\n",
    "            #tf.print(\"\\nP is\", self.p)  # 使用 tf.print\n",
    "        else:\n",
    "            mask = tf.ones([1, 1, 1, self.filters], dtype=tf.float32) * self.p\n",
    "    \n",
    "        sparse_kernel = self.kernel * mask\n",
    "        conv = tf.nn.conv2d(inputs, sparse_kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        return tf.nn.bias_add(conv, self.bias)\n",
    "\n",
    "    @tf.function\n",
    "    def update_p(self, new_p):\n",
    "        self.p.assign(float(new_p))  # 使用 assign 更新 tf.Variable 的值，并转换为浮点数\n",
    "        #tf.print(\"\\nEpoch counter is\", self.counter)  # 使用 tf.print\n",
    "        #tf.print(\"\\nP is\", self.p)  # 使用 tf.print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af584832-32c4-4de9-b939-67177aa1f8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "sparse_conv2d_1 (SparseConv2 (None, 28, 28, 32)        322       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "sparse_conv2d_2 (SparseConv2 (None, 14, 14, 64)        18498     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "sparse_conv2d_3 (SparseConv2 (None, 7, 7, 128)         73858     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 904,528\n",
      "Trainable params: 904,522\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28, 1))  # Adjusted input shape for MNIST\n",
    "x = SparseConv2D(filters=32, kernel_size=3, p=1, name='sparse_conv2d_1')(inputs)  # 第一个稀疏卷积层\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = SparseConv2D(filters=64, kernel_size=3, p=1, name='sparse_conv2d_2')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = SparseConv2D(filters=128, kernel_size=3, p=1, name='sparse_conv2d_3')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)  # Adjusted for 10 classes of MNIST\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ed562d-2bb0-428c-9b45-450d274f6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatePSparsity(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, sparsity_schedule):\n",
    "        super(UpdatePSparsity, self).__init__()\n",
    "        self.model = model\n",
    "        self.sparsity_schedule = sparsity_schedule\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for layer_name, new_p in self.sparsity_schedule.items():\n",
    "            layer = self.model.get_layer(name=layer_name)\n",
    "            if epoch < len(new_p):\n",
    "                p_value = new_p[epoch]\n",
    "            else:\n",
    "                p_value = new_p[-1]  # Use the last value for epochs beyond the predefined ones\n",
    "            layer.update_p(p_value)\n",
    "\n",
    "sparsity_schedule = {\n",
    "    'sparse_conv2d_1': [1.0],\n",
    "    'sparse_conv2d_2': [1.0],\n",
    "    'sparse_conv2d_3': [1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7da4c9e-89ea-41d4-8459-818726bf82d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - 4s 2ms/step - loss: 0.4867 - accuracy: 0.8223 - val_loss: 0.3469 - val_accuracy: 0.8778\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2942 - accuracy: 0.8932 - val_loss: 0.2884 - val_accuracy: 0.8930\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2454 - accuracy: 0.9110 - val_loss: 0.2672 - val_accuracy: 0.9025\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2164 - accuracy: 0.9208 - val_loss: 0.2678 - val_accuracy: 0.9017\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1921 - accuracy: 0.9287 - val_loss: 0.2340 - val_accuracy: 0.9143\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1694 - accuracy: 0.9365 - val_loss: 0.2513 - val_accuracy: 0.9126\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1491 - accuracy: 0.9445 - val_loss: 0.2314 - val_accuracy: 0.9184\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1312 - accuracy: 0.9515 - val_loss: 0.2303 - val_accuracy: 0.9193\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1141 - accuracy: 0.9565 - val_loss: 0.2467 - val_accuracy: 0.9230\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0967 - accuracy: 0.9633 - val_loss: 0.2640 - val_accuracy: 0.9217\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0820 - accuracy: 0.9685 - val_loss: 0.2497 - val_accuracy: 0.9229\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0684 - accuracy: 0.9744 - val_loss: 0.2975 - val_accuracy: 0.9221\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0587 - accuracy: 0.9783 - val_loss: 0.2854 - val_accuracy: 0.9216\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0503 - accuracy: 0.9816 - val_loss: 0.3073 - val_accuracy: 0.9205\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0450 - accuracy: 0.9828 - val_loss: 0.3566 - val_accuracy: 0.9199\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0381 - accuracy: 0.9864 - val_loss: 0.3583 - val_accuracy: 0.9224\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0337 - accuracy: 0.9875 - val_loss: 0.3851 - val_accuracy: 0.9249\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0317 - accuracy: 0.9883 - val_loss: 0.3990 - val_accuracy: 0.9206\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 0.3723 - val_accuracy: 0.9199\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.4599 - val_accuracy: 0.9178\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 0.4284 - val_accuracy: 0.9263\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.4225 - val_accuracy: 0.9219\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.4926 - val_accuracy: 0.9162\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 0.4663 - val_accuracy: 0.9228\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.5349 - val_accuracy: 0.9226\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.4767 - val_accuracy: 0.9204\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.5076 - val_accuracy: 0.9204\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.6068 - val_accuracy: 0.9137\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.5332 - val_accuracy: 0.9240\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.5040 - val_accuracy: 0.9198\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.5293 - val_accuracy: 0.9196\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.5749 - val_accuracy: 0.9164\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.4867 - val_accuracy: 0.9198\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.5891 - val_accuracy: 0.9139\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.5897 - val_accuracy: 0.9189\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.5714 - val_accuracy: 0.9230\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.5509 - val_accuracy: 0.9183\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.5586 - val_accuracy: 0.9239\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.5886 - val_accuracy: 0.9225\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.6062 - val_accuracy: 0.9247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ecc6542b08>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(mnist_train_images, mnist_train_labels, epochs=40, batch_size=128, validation_data=(mnist_test_images, mnist_test_labels), callbacks=[UpdatePSparsity(model, sparsity_schedule)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
